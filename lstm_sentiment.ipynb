{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-term Memory for Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses LSTM neural network on the [IMDB sentiment classification](https://keras.io/api/datasets/imdb/) task. This is a dataset for binary sentiment classification. 25,000 highly polar movie reviews are provided for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "IMDB sentiment dataset is available in keras.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_data in module keras.datasets.imdb:\n",
      "\n",
      "load_data(path='imdb.npz', num_words=None, skip_top=0, maxlen=None, seed=113, start_char=1, oov_char=2, index_from=3, **kwargs)\n",
      "    Loads the [IMDB dataset](https://ai.stanford.edu/~amaas/data/sentiment/).\n",
      "    \n",
      "    This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment\n",
      "    (positive/negative). Reviews have been preprocessed, and each review is\n",
      "    encoded as a list of word indexes (integers).\n",
      "    For convenience, words are indexed by overall frequency in the dataset,\n",
      "    so that for instance the integer \"3\" encodes the 3rd most frequent word in\n",
      "    the data. This allows for quick filtering operations such as:\n",
      "    \"only consider the top 10,000 most\n",
      "    common words, but eliminate the top 20 most common words\".\n",
      "    \n",
      "    As a convention, \"0\" does not stand for a specific word, but instead is used\n",
      "    to encode any unknown word.\n",
      "    \n",
      "    Args:\n",
      "      path: where to cache the data (relative to `~/.keras/dataset`).\n",
      "      num_words: integer or None. Words are\n",
      "          ranked by how often they occur (in the training set) and only\n",
      "          the `num_words` most frequent words are kept. Any less frequent word\n",
      "          will appear as `oov_char` value in the sequence data. If None,\n",
      "          all words are kept. Defaults to None, so all words are kept.\n",
      "      skip_top: skip the top N most frequently occurring words\n",
      "          (which may not be informative). These words will appear as\n",
      "          `oov_char` value in the dataset. Defaults to 0, so no words are\n",
      "          skipped.\n",
      "      maxlen: int or None. Maximum sequence length.\n",
      "          Any longer sequence will be truncated. Defaults to None, which\n",
      "          means no truncation.\n",
      "      seed: int. Seed for reproducible data shuffling.\n",
      "      start_char: int. The start of a sequence will be marked with this\n",
      "          character. Defaults to 1 because 0 is usually the padding character.\n",
      "      oov_char: int. The out-of-vocabulary character.\n",
      "          Words that were cut out because of the `num_words` or\n",
      "          `skip_top` limits will be replaced with this character.\n",
      "      index_from: int. Index actual words with this index and higher.\n",
      "      **kwargs: Used for backwards compatibility.\n",
      "    \n",
      "    Returns:\n",
      "      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
      "    \n",
      "    **x_train, x_test**: lists of sequences, which are lists of indexes\n",
      "      (integers). If the num_words argument was specific, the maximum\n",
      "      possible index value is `num_words - 1`. If the `maxlen` argument was\n",
      "      specified, the largest possible sequence length is `maxlen`.\n",
      "    \n",
      "    **y_train, y_test**: lists of integer labels (1 or 0).\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: in case `maxlen` is so low\n",
      "          that no input sequence could be kept.\n",
      "    \n",
      "    Note that the 'out of vocabulary' character is only used for\n",
      "    words that were present in the training set but are not included\n",
      "    because they're not making the `num_words` cut here.\n",
      "    Words that were not seen in the training set but are in the test set\n",
      "    have simply been skipped.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(imdb.load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "# maxlen: cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Keras has already preprocessed the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (25000, 80)\n",
      "X_test shape: (25000, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 125,   68,    2, 6853,   15,  349,  165, 4362,   98,    5,    4,\n",
       "        228,    9,   43,    2, 1157,   15,  299,  120,    5,  120,  174,\n",
       "         11,  220,  175,  136,   50,    9, 4373,  228, 8255,    5,    2,\n",
       "        656,  245, 2350,    5,    4, 9837,  131,  152,  491,   18,    2,\n",
       "         32, 7464, 1212,   14,    9,    6,  371,   78,   22,  625,   64,\n",
       "       1382,    9,    8,  168,  145,   23,    4, 1690,   15,   16,    4,\n",
       "       1355,    5,   28,    6,   52,  154,  462,   33,   89,   78,  285,\n",
       "         16,  145,   95])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.SimpleRNN(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid')) #sigmoid --> binary/ multiple classes: softmax\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          320000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                1568      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,601\n",
      "Trainable params: 321,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 8s 20ms/step - loss: 0.7005 - accuracy: 0.5188 - val_loss: 0.6781 - val_accuracy: 0.5812\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.6445 - accuracy: 0.6144 - val_loss: 0.5822 - val_accuracy: 0.7016\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.4898 - accuracy: 0.7721 - val_loss: 0.4282 - val_accuracy: 0.8076\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.4141 - accuracy: 0.8201 - val_loss: 0.4178 - val_accuracy: 0.8188\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.3728 - accuracy: 0.8429 - val_loss: 0.6961 - val_accuracy: 0.7614\n",
      "Epoch 6/32\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3383 - accuracy: 0.8613 - val_loss: 0.3967 - val_accuracy: 0.8282\n",
      "Epoch 7/32\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3170 - accuracy: 0.8744 - val_loss: 0.4480 - val_accuracy: 0.8314\n",
      "Epoch 8/32\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2968 - accuracy: 0.8838 - val_loss: 0.4538 - val_accuracy: 0.8278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abb8e9ba90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 82.26%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN using the entire sequence instead of the last output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 80, 16)            320000    \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 80, 32)            1568      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2561      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,129\n",
      "Trainable params: 324,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16, input_length=maxlen))\n",
    "model.add(layers.SimpleRNN(32, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)) #return_sequences=True,\n",
    "model.add(layers.Flatten()) #difference\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 7s 20ms/step - loss: 0.7013 - accuracy: 0.5156 - val_loss: 0.6642 - val_accuracy: 0.5926\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.4885 - accuracy: 0.7577 - val_loss: 0.3732 - val_accuracy: 0.8396\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.3249 - accuracy: 0.8616 - val_loss: 0.3504 - val_accuracy: 0.8440\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2703 - accuracy: 0.8868 - val_loss: 0.3517 - val_accuracy: 0.8488\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2357 - accuracy: 0.9061 - val_loss: 0.3661 - val_accuracy: 0.8482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abc1fe98b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 84.17%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 16)          320000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               74240     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 394,369\n",
      "Trainable params: 394,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 32s 94ms/step - loss: 0.5304 - accuracy: 0.7358 - val_loss: 0.3666 - val_accuracy: 0.8378\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 0.3391 - accuracy: 0.8613 - val_loss: 0.3681 - val_accuracy: 0.8434\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 0.2857 - accuracy: 0.8853 - val_loss: 0.3620 - val_accuracy: 0.8440\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.2520 - accuracy: 0.9004 - val_loss: 0.3544 - val_accuracy: 0.8434\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 0.2307 - accuracy: 0.9125 - val_loss: 0.4855 - val_accuracy: 0.8324\n",
      "Epoch 6/32\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 0.2124 - accuracy: 0.9194 - val_loss: 0.3714 - val_accuracy: 0.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abb81b88e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 83.10%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 16)          320000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 128)         74240     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 525,953\n",
      "Trainable params: 525,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 90s 275ms/step - loss: 0.5127 - accuracy: 0.7369 - val_loss: 0.4166 - val_accuracy: 0.8228\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 108s 345ms/step - loss: 0.3287 - accuracy: 0.8629 - val_loss: 0.3897 - val_accuracy: 0.8268\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 104s 333ms/step - loss: 0.2790 - accuracy: 0.8866 - val_loss: 0.3626 - val_accuracy: 0.8418\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 110s 353ms/step - loss: 0.2492 - accuracy: 0.9020 - val_loss: 0.3612 - val_accuracy: 0.8464\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 110s 353ms/step - loss: 0.2256 - accuracy: 0.9139 - val_loss: 0.4048 - val_accuracy: 0.8368\n",
      "Epoch 6/32\n",
      "313/313 [==============================] - 111s 354ms/step - loss: 0.2119 - accuracy: 0.9196 - val_loss: 0.4254 - val_accuracy: 0.8426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abb90ccf70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 83.53%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 16)          320000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              148480    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 468,737\n",
      "Trainable params: 468,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 74s 222ms/step - loss: 0.5246 - accuracy: 0.7365 - val_loss: 0.3829 - val_accuracy: 0.8352\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 87s 279ms/step - loss: 0.3359 - accuracy: 0.8602 - val_loss: 0.3953 - val_accuracy: 0.8412\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 90s 289ms/step - loss: 0.2743 - accuracy: 0.8908 - val_loss: 0.4490 - val_accuracy: 0.8216\n",
      "Testing set accuracy: 82.28%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])\n",
    "\n",
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 82.28%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
