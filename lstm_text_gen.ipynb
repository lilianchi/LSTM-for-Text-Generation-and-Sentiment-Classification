{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-term Memory for Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses LSTM neural network to generate text from Nietzsche's writings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "Nietzsche's writing dataset is available online. The following code download the dataset.\n",
    "https://s3.amazonaws.com/text-datasets/nietzsche.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supposing that truth is a woman--what then? is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to truth, have been unskilled and unseemly methods for\n",
      "winning a woman? certainly she has never allowed herself to be won; and\n",
      "at present every kind of dogma stands with sad and discouraged mien--if,\n",
      "indeed, it stands at all!\n"
     ]
    }
   ],
   "source": [
    "print(text[10:513])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "# total nomber of characters\n",
    "print('total chars:', len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data\n",
    "\n",
    "We cut the text in sequences of maxlen characters with a jump size of 3.\n",
    "The features for each example is a matrix of size maxlen*num of chars.\n",
    "The label for each example is a vector of size num of chars, which represents the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create (character, index) and (index, character) dictionary\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-b1fdc504c468>:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "<ipython-input-8-b1fdc504c468>:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200285, 40, 57)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200285, 57)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model - fill in this box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(maxlen, len(chars))),\n",
    "        layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "        layers.Dense(len(chars), activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               95232     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 57)                7353      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,585\n",
      "Trainable params: 102,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PrintLoss(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, _):\n",
    "        # Function invoked at end of each epoch. Prints generated text.\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "        for diversity in [0.5, 1.0]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill in this box for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1252/1252 [==============================] - 90s 71ms/step - loss: 2.6601 - accuracy: 0.2518 - val_loss: 2.3412 - val_accuracy: 0.3298\n",
      "Epoch 2/40\n",
      "1252/1252 [==============================] - 97s 77ms/step - loss: 2.3574 - accuracy: 0.3182 - val_loss: 2.1625 - val_accuracy: 0.3657\n",
      "Epoch 3/40\n",
      "1252/1252 [==============================] - 94s 75ms/step - loss: 2.2265 - accuracy: 0.3529 - val_loss: 2.0565 - val_accuracy: 0.3954\n",
      "Epoch 4/40\n",
      "1252/1252 [==============================] - 91s 73ms/step - loss: 2.1348 - accuracy: 0.3770 - val_loss: 1.9775 - val_accuracy: 0.4144\n",
      "Epoch 5/40\n",
      "1252/1252 [==============================] - 92s 73ms/step - loss: 2.0710 - accuracy: 0.3935 - val_loss: 1.9166 - val_accuracy: 0.4331\n",
      "Epoch 6/40\n",
      "1252/1252 [==============================] - 92s 74ms/step - loss: 2.0164 - accuracy: 0.4072 - val_loss: 1.8741 - val_accuracy: 0.4424\n",
      "Epoch 7/40\n",
      "1252/1252 [==============================] - 92s 74ms/step - loss: 1.9749 - accuracy: 0.4193 - val_loss: 1.8332 - val_accuracy: 0.4564\n",
      "Epoch 8/40\n",
      "1252/1252 [==============================] - 96s 77ms/step - loss: 1.9386 - accuracy: 0.4285 - val_loss: 1.8051 - val_accuracy: 0.4634\n",
      "Epoch 9/40\n",
      "1252/1252 [==============================] - 92s 74ms/step - loss: 1.9066 - accuracy: 0.4375 - val_loss: 1.7790 - val_accuracy: 0.4700\n",
      "Epoch 10/40\n",
      "1252/1252 [==============================] - 92s 74ms/step - loss: 1.8836 - accuracy: 0.4446 - val_loss: 1.7597 - val_accuracy: 0.4731\n",
      "Epoch 11/40\n",
      "1252/1252 [==============================] - 93s 74ms/step - loss: 1.8596 - accuracy: 0.4506 - val_loss: 1.7396 - val_accuracy: 0.4824\n",
      "Epoch 12/40\n",
      "1252/1252 [==============================] - 93s 75ms/step - loss: 1.8427 - accuracy: 0.4548 - val_loss: 1.7196 - val_accuracy: 0.4884\n",
      "Epoch 13/40\n",
      "1252/1252 [==============================] - 92s 74ms/step - loss: 1.8260 - accuracy: 0.4587 - val_loss: 1.7034 - val_accuracy: 0.4936\n",
      "Epoch 14/40\n",
      "1252/1252 [==============================] - 94s 75ms/step - loss: 1.8074 - accuracy: 0.4642 - val_loss: 1.6982 - val_accuracy: 0.4962\n",
      "Epoch 15/40\n",
      "1252/1252 [==============================] - 94s 75ms/step - loss: 1.7965 - accuracy: 0.4672 - val_loss: 1.6832 - val_accuracy: 0.5011\n",
      "Epoch 16/40\n",
      "1252/1252 [==============================] - 93s 75ms/step - loss: 1.7832 - accuracy: 0.4722 - val_loss: 1.6677 - val_accuracy: 0.5035\n",
      "Epoch 17/40\n",
      "1252/1252 [==============================] - 94s 75ms/step - loss: 1.7719 - accuracy: 0.4746 - val_loss: 1.6587 - val_accuracy: 0.5050\n",
      "Epoch 18/40\n",
      "1252/1252 [==============================] - 94s 75ms/step - loss: 1.7616 - accuracy: 0.4772 - val_loss: 1.6538 - val_accuracy: 0.5093\n",
      "Epoch 19/40\n",
      "1252/1252 [==============================] - 94s 75ms/step - loss: 1.7533 - accuracy: 0.4780 - val_loss: 1.6436 - val_accuracy: 0.5121\n",
      "Epoch 20/40\n",
      "1252/1252 [==============================] - 95s 76ms/step - loss: 1.7449 - accuracy: 0.4829 - val_loss: 1.6359 - val_accuracy: 0.5131\n",
      "Epoch 21/40\n",
      "1252/1252 [==============================] - 101s 81ms/step - loss: 1.7377 - accuracy: 0.4834 - val_loss: 1.6312 - val_accuracy: 0.5140\n",
      "Epoch 22/40\n",
      "1252/1252 [==============================] - 97s 77ms/step - loss: 1.7277 - accuracy: 0.4865 - val_loss: 1.6220 - val_accuracy: 0.5171\n",
      "Epoch 23/40\n",
      "1252/1252 [==============================] - 97s 77ms/step - loss: 1.7224 - accuracy: 0.4882 - val_loss: 1.6171 - val_accuracy: 0.5170\n",
      "Epoch 24/40\n",
      "1252/1252 [==============================] - 97s 77ms/step - loss: 1.7147 - accuracy: 0.4900 - val_loss: 1.6114 - val_accuracy: 0.5207\n",
      "Epoch 25/40\n",
      "1252/1252 [==============================] - 95s 76ms/step - loss: 1.7106 - accuracy: 0.4899 - val_loss: 1.6111 - val_accuracy: 0.5202\n",
      "Epoch 26/40\n",
      "1252/1252 [==============================] - 93s 74ms/step - loss: 1.7031 - accuracy: 0.4924 - val_loss: 1.6041 - val_accuracy: 0.5231\n",
      "Epoch 27/40\n",
      "1252/1252 [==============================] - 98s 79ms/step - loss: 1.7001 - accuracy: 0.4935 - val_loss: 1.6008 - val_accuracy: 0.5216\n",
      "Epoch 28/40\n",
      "1252/1252 [==============================] - 99s 79ms/step - loss: 1.6972 - accuracy: 0.4949 - val_loss: 1.5984 - val_accuracy: 0.5233\n",
      "Epoch 29/40\n",
      "1252/1252 [==============================] - 96s 77ms/step - loss: 1.6919 - accuracy: 0.4965 - val_loss: 1.5933 - val_accuracy: 0.5259\n",
      "Epoch 30/40\n",
      "1252/1252 [==============================] - 93s 74ms/step - loss: 1.6876 - accuracy: 0.4966 - val_loss: 1.5876 - val_accuracy: 0.5282\n",
      "Epoch 31/40\n",
      "1252/1252 [==============================] - 93s 74ms/step - loss: 1.6857 - accuracy: 0.4980 - val_loss: 1.5876 - val_accuracy: 0.5283\n",
      "Epoch 32/40\n",
      "1252/1252 [==============================] - 93s 74ms/step - loss: 1.6807 - accuracy: 0.4994 - val_loss: 1.5861 - val_accuracy: 0.5285\n",
      "Epoch 33/40\n",
      "1252/1252 [==============================] - 95s 76ms/step - loss: 1.6766 - accuracy: 0.4997 - val_loss: 1.5802 - val_accuracy: 0.5288\n",
      "Epoch 34/40\n",
      "1252/1252 [==============================] - 93s 75ms/step - loss: 1.6768 - accuracy: 0.5008 - val_loss: 1.5765 - val_accuracy: 0.5303\n",
      "Epoch 35/40\n",
      "1252/1252 [==============================] - 93s 74ms/step - loss: 1.6709 - accuracy: 0.5020 - val_loss: 1.5785 - val_accuracy: 0.5304\n",
      "Epoch 36/40\n",
      "1252/1252 [==============================] - 94s 75ms/step - loss: 1.6691 - accuracy: 0.5024 - val_loss: 1.5732 - val_accuracy: 0.5315\n",
      "Epoch 37/40\n",
      "1252/1252 [==============================] - 99s 79ms/step - loss: 1.6666 - accuracy: 0.5028 - val_loss: 1.5696 - val_accuracy: 0.5329\n",
      "Epoch 38/40\n",
      "1252/1252 [==============================] - 93s 75ms/step - loss: 1.6647 - accuracy: 0.5037 - val_loss: 1.5713 - val_accuracy: 0.5342\n",
      "Epoch 39/40\n",
      "1252/1252 [==============================] - 98s 79ms/step - loss: 1.6607 - accuracy: 0.5050 - val_loss: 1.5692 - val_accuracy: 0.5349\n",
      "Epoch 40/40\n",
      "1252/1252 [==============================] - 98s 78ms/step - loss: 1.6584 - accuracy: 0.5050 - val_loss: 1.5643 - val_accuracy: 0.5340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a6357d820>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "BATCH = 128\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "model.fit(x, y, batch_size=BATCH, epochs=EPOCHS, validation_split=0.2,\n",
    "          verbose = 1, callbacks = [early_stop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
